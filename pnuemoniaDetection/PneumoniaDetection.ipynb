{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 # for image resizing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "print(os.listdir(\"./chest_xray/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(87)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.set_random_seed(87)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to the data directory\n",
    "data_dir = Path('./chest_xray')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3875\n",
      "0    1341\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chest_xray\\train\\NORMAL\\IM-0584-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chest_xray\\train\\NORMAL\\NORMAL2-IM-0423-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chest_xray\\train\\PNEUMONIA\\person1463_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chest_xray\\train\\PNEUMONIA\\person1467_virus_25...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chest_xray\\train\\PNEUMONIA\\person1052_virus_17...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0          chest_xray\\train\\NORMAL\\IM-0584-0001.jpeg      0\n",
       "1  chest_xray\\train\\NORMAL\\NORMAL2-IM-0423-0001.jpeg      0\n",
       "2  chest_xray\\train\\PNEUMONIA\\person1463_bacteria...      1\n",
       "3  chest_xray\\train\\PNEUMONIA\\person1467_virus_25...      1\n",
       "4  chest_xray\\train\\PNEUMONIA\\person1052_virus_17...      1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img,0))\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img,1))\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=['image','label'],index = None)\n",
    "\n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of validation examples:  (16, 128, 128, 3)\n",
      "Total number of labels: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "\n",
    "# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n",
    "# We will normalize the pixel values and resizing all the images to 224x224 \n",
    "\n",
    "# Normal cases\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (128,128))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "                      \n",
    "# Pneumonia cases        \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (128,128))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence \n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, imsize):\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    batch_data = np.zeros((batch_size,imsize,imsize,3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    i=0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j,idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "            \n",
    "            #onde hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (imsize,imsize))\n",
    "            \n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            \n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "            \n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "            \n",
    "            if label == 0 and count < batch_size-2:\n",
    "                aug_img1 = seq.augment_image(img)\n",
    "                aug_img2 = seq.augment_image(img)\n",
    "                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "                \n",
    "                batch_data[count+1] = aug_img1\n",
    "                batch_labels[count+1] = encoded_label\n",
    "                batch_data[count+2] = aug_img2\n",
    "                batch_labels[count+2] = encoded_label\n",
    "                count+=2\n",
    "            else:\n",
    "                count+=1\n",
    "                \n",
    "            if count == batch_size-1:\n",
    "                break\n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "        \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_128_model():\n",
    "    input_img = Input(shape=(128,128,3), name='ImageInput')\n",
    "    x = Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv1_1\")(input_img)\n",
    "    x = Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv1_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_1\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2),name=\"pool_1\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv2_1\")(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv2_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2),name=\"pool_2\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv3_1\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv3_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_3\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2),name=\"pool_3\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512,activation=\"relu\", name=\"fc_1\")(x)\n",
    "    x = BatchNormalization(name=\"bn_4\")(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    x = Dense(256,activation=\"relu\", name=\"fc_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_5\")(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    x = Dense(2,activation=\"softmax\",name=\"fc_3\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (Conv2D)             (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (Conv2D)             (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (Conv2D)             (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Conv3_2 (Conv2D)             (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "bn_4 (BatchNormalization)    (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "bn_5 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc_3 (Dense)                 (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 8,596,562\n",
      "Trainable params: 8,594,802\n",
      "Non-trainable params: 1,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_128 = build_128_model()\n",
    "model_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
    "model_128.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation steps: 326 and 16\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "nb_epochs = 20\n",
    "\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size, imsize=128)\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator()\n",
    "valid_batches = gen.flow_from_directory(\"chest_xray/val\", model_128.input_shape[1:3],color_mode=\"grayscale\", shuffle=True,seed=1,\n",
    "                                        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.0583 - acc: 0.9818 - val_loss: 1.8072 - val_acc: 0.5625\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.0596 - acc: 0.9793 - val_loss: 0.7763 - val_acc: 0.7500\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0534 - acc: 0.9833 - val_loss: 1.3747 - val_acc: 0.5625\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 68s 209ms/step - loss: 0.0641 - acc: 0.9781 - val_loss: 0.4663 - val_acc: 0.8125\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 69s 210ms/step - loss: 0.0687 - acc: 0.9793 - val_loss: 0.9819 - val_acc: 0.8125\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.0569 - acc: 0.9822 - val_loss: 0.2309 - val_acc: 0.8750\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0511 - acc: 0.9866 - val_loss: 0.8941 - val_acc: 0.6875\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 68s 210ms/step - loss: 0.0479 - acc: 0.9843 - val_loss: 2.1061 - val_acc: 0.5625\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0439 - acc: 0.9835 - val_loss: 0.1615 - val_acc: 0.9375\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 67s 205ms/step - loss: 0.0489 - acc: 0.9852 - val_loss: 2.3752 - val_acc: 0.6250\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 0.0485 - acc: 0.9837 - val_loss: 0.8743 - val_acc: 0.7500\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 68s 209ms/step - loss: 0.0519 - acc: 0.9824 - val_loss: 0.5548 - val_acc: 0.8750\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0433 - acc: 0.9862 - val_loss: 0.1071 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 68s 208ms/step - loss: 0.0436 - acc: 0.9849 - val_loss: 0.2774 - val_acc: 0.8750\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 67s 205ms/step - loss: 0.0344 - acc: 0.9887 - val_loss: 0.1909 - val_acc: 0.8750\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0431 - acc: 0.9868 - val_loss: 0.2092 - val_acc: 0.8125\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0329 - acc: 0.9887 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.0474 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 68s 208ms/step - loss: 0.0273 - acc: 0.9923 - val_loss: 0.1157 - val_acc: 0.9375- loss: 0.0253 - acc: \n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0346 - acc: 0.9900 - val_loss: 0.0561 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist_128 = model_128.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps, validation_data=(valid_data, valid_labels) , callbacks=[es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_128.load_weights(\"best_model_todate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples:  (624, 128, 128, 3)\n",
      "Total number of labels: (624, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (128,128))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "                      \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (128,128))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 1ms/step\n",
      "Loss on test set:  1.173952668516181\n",
      "Accuracy on test set:  0.7900641025641025\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "test_loss, test_score = model_128.evaluate(test_data, test_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624,)\n",
      "(624,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = model_128.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(orig_test_labels.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model is 0.98\n",
      "Precision of the model is 0.76\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of validation examples:  (16, 64, 64, 3)\n",
      "Total number of labels: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "valid_data_64 = []\n",
    "valid_labels_64 = []\n",
    "\n",
    "\n",
    "# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n",
    "# We will normalize the pixel values and resizing all the images to 224x224 \n",
    "\n",
    "# Normal cases\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    valid_data_64.append(img)\n",
    "    valid_labels_64.append(label)\n",
    "                      \n",
    "# Pneumonia cases        \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    valid_data_64.append(img)\n",
    "    valid_labels_64.append(label)\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "valid_data_64 = np.array(valid_data_64)\n",
    "valid_labels_64 = np.array(valid_labels_64)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data_64.shape)\n",
    "print(\"Total number of labels:\", valid_labels_64.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_64_model():\n",
    "    input_img = Input(shape=(64,64,3), name='ImageInput')\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv1_1\")(input_img)\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv1_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_1\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2),name=\"pool_1\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv2_1\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\",padding=\"same\", name=\"Conv2_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2),name=\"pool_2\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation=\"relu\", name=\"fc_1\")(x)\n",
    "    x = BatchNormalization(name=\"bn_3\")(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    x = Dense(2,activation=\"softmax\",name=\"fc_2\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (Conv2D)             (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Conv2_2 (Conv2D)             (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,262,050\n",
      "Trainable params: 4,261,346\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_64 = build_64_model()\n",
    "model_64.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath='best_model_64_todate', save_best_only=True, save_weights_only=True)\n",
    "model_64.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation steps: 326 and 16\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "nb_epochs = 20\n",
    "\n",
    "train_data_gen_64 = data_gen(data=train_data, batch_size=batch_size, imsize=64)\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 288s 884ms/step - loss: 0.2240 - acc: 0.9183 - val_loss: 1.0168 - val_acc: 0.5625\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.1569 - acc: 0.9444 - val_loss: 0.2811 - val_acc: 0.8125\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.1238 - acc: 0.9525 - val_loss: 1.7445 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 75s 229ms/step - loss: 0.1124 - acc: 0.9599 - val_loss: 0.2883 - val_acc: 0.8750\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.0968 - acc: 0.9659 - val_loss: 1.5333 - val_acc: 0.5625\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 74s 228ms/step - loss: 0.1025 - acc: 0.9643 - val_loss: 0.9290 - val_acc: 0.6250\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 74s 227ms/step - loss: 0.1004 - acc: 0.9661 - val_loss: 0.5206 - val_acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "hist_64 = model_64.fit_generator(train_data_gen_64, epochs=nb_epochs, steps_per_epoch=nb_train_steps, validation_data=(valid_data_64, valid_labels_64) , callbacks=[es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_64.load_weights(\"best_model_64_todate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples:  (624, 64, 64, 3)\n",
      "Total number of labels: (624, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "                      \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 943us/step\n",
      "Loss on test set:  0.503340585825917\n",
      "Accuracy on test set:  0.8044871794871795\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "test_loss, test_score = model_64.evaluate(test_data, test_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624,)\n",
      "(624,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = model_64.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(orig_test_labels.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model is 0.97\n",
      "Precision of the model is 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
